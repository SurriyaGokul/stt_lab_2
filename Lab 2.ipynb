{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26cdd9e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No sentence-transformers model found with name microsoft/codebert-base. Creating a new one with mean pooling.\n",
      "c:\\Users\\Surrya Gokul\\anaconda3\\envs\\genai\\Lib\\site-packages\\huggingface_hub\\file_download.py:143: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\Surrya Gokul\\.cache\\huggingface\\hub\\models--microsoft--codebert-base. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n",
      "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n",
      "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n",
      "c:\\Users\\Surrya Gokul\\anaconda3\\envs\\genai\\Lib\\site-packages\\huggingface_hub\\file_download.py:143: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\Surrya Gokul\\.cache\\huggingface\\hub\\models--mamiksik--CommitPredictorT5. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n",
      "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "import torch\n",
    "\n",
    "# ---------- 2. Load models ----------\n",
    "# Model for semantic similarity\n",
    "sim_model = SentenceTransformer(\"microsoft/codebert-base\")\n",
    "\n",
    "# Commit predictor model (for rectification)\n",
    "pred_model_name = \"mamiksik/CommitPredictorT5\"\n",
    "pred_tokenizer = AutoTokenizer.from_pretrained(pred_model_name)\n",
    "pred_model = AutoModelForSeq2SeqLM.from_pretrained(pred_model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45aab894",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating commits: 100%|██████████| 979/979 [1:51:09<00:00,  6.81s/it]  \n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "import torch\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "pred_model = pred_model.to(device)\n",
    "\n",
    "def batch_rectify_messages(diffs, batch_size=16):\n",
    "    cleaned = [clean_diff(d) for d in diffs]\n",
    "    results = []\n",
    "\n",
    "    # tqdm gives ETA automatically\n",
    "    for i in tqdm(range(0, len(cleaned), batch_size), desc=\"Generating commits\"):\n",
    "        batch = cleaned[i:i+batch_size]\n",
    "        inputs = pred_tokenizer(\n",
    "            batch,\n",
    "            return_tensors=\"pt\",\n",
    "            truncation=True,\n",
    "            max_length=512,\n",
    "            padding=True\n",
    "        ).to(device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            outputs = pred_model.generate(**inputs, max_length=64)\n",
    "\n",
    "        decoded = pred_tokenizer.batch_decode(outputs, skip_special_tokens=True)\n",
    "        results.extend(decoded)\n",
    "\n",
    "    return results\n",
    "\n",
    "df[\"LLM Inference\"] = batch_rectify_messages(df[\"Diff\"].tolist(), batch_size=16)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f85d35ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"llm_inference.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8fc63b87",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv(\"llm_inference.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6b0603e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Hash</th>\n",
       "      <th>Message</th>\n",
       "      <th>Hashes of parents</th>\n",
       "      <th>Is a merge commit?</th>\n",
       "      <th>Filename</th>\n",
       "      <th>Source Code (before)</th>\n",
       "      <th>Source Code (current)</th>\n",
       "      <th>Diff</th>\n",
       "      <th>LLM Inference</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>d2fdcba29db2a88056cfa87d9abfbdde840bd8c2</td>\n",
       "      <td>fix test name (#22)</td>\n",
       "      <td>21b10ffb130aeac3131899e551939338b0dcebef</td>\n",
       "      <td>No</td>\n",
       "      <td>test_openai.py</td>\n",
       "      <td>\"\"\"Test OpenAI API wrapper.\"\"\"\\n\\nfrom langcha...</td>\n",
       "      <td>\"\"\"Test OpenAI API wrapper.\"\"\"\\n\\nfrom langcha...</td>\n",
       "      <td>@@ -3,8 +3,8 @@\\n from langchain.llms.openai i...</td>\n",
       "      <td>add missing docstring</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6a3dca888ba75e219185c54cd0f0ba72d1f90a26</td>\n",
       "      <td>Fix cohere integration (#33)\\n\\nCurrently the ...</td>\n",
       "      <td>c7f9c62532f8137db2c4ab80335ac1472e79d56a</td>\n",
       "      <td>No</td>\n",
       "      <td>cohere.py</td>\n",
       "      <td>\"\"\"Wrapper around Cohere APIs.\"\"\"\\nimport os\\n...</td>\n",
       "      <td>\"\"\"Wrapper around Cohere APIs.\"\"\"\\nimport os\\n...</td>\n",
       "      <td>@@ -22,7 +22,7 @@ class Cohere(BaseModel, LLM)...</td>\n",
       "      <td>model attribute for gptd-instruct-tft</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>90a6e578bc8d2147f5fcc22d6413686027eca2b5</td>\n",
       "      <td>fix type hint (#34)</td>\n",
       "      <td>6a3dca888ba75e219185c54cd0f0ba72d1f90a26</td>\n",
       "      <td>No</td>\n",
       "      <td>cohere.py</td>\n",
       "      <td>\"\"\"Wrapper around Cohere APIs.\"\"\"\\nimport os\\n...</td>\n",
       "      <td>\"\"\"Wrapper around Cohere APIs.\"\"\"\\nimport os\\n...</td>\n",
       "      <td>@@ -22,7 +22,7 @@ class Cohere(BaseModel, LLM)...</td>\n",
       "      <td>model attribute for model_name_to_json</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>eb36317f9ae6054a9bbf62ac7ceb8bae388ee811</td>\n",
       "      <td>Harrison/fix imports (#72)\\n\\nfix imports and ...</td>\n",
       "      <td>a5b61d59e193c4f9804c9dece7bd1a1c5c1103e0</td>\n",
       "      <td>No</td>\n",
       "      <td>embeddings.ipynb</td>\n",
       "      <td>{\\n \"cells\": [\\n  {\\n   \"cell_type\": \"code\",\\n...</td>\n",
       "      <td>{\\n \"cells\": [\\n  {\\n   \"cell_type\": \"code\",\\n...</td>\n",
       "      <td>@@ -5,11 +5,26 @@\\n    \"execution_count\": 1,\\n...</td>\n",
       "      <td>update error message</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>eb36317f9ae6054a9bbf62ac7ceb8bae388ee811</td>\n",
       "      <td>Harrison/fix imports (#72)\\n\\nfix imports and ...</td>\n",
       "      <td>a5b61d59e193c4f9804c9dece7bd1a1c5c1103e0</td>\n",
       "      <td>No</td>\n",
       "      <td>mrkl.ipynb</td>\n",
       "      <td>{\\n \"cells\": [\\n  {\\n   \"cell_type\": \"code\",\\n...</td>\n",
       "      <td>{\\n \"cells\": [\\n  {\\n   \"cell_type\": \"markdown...</td>\n",
       "      <td>@@ -1,5 +1,14 @@\\n {\\n  \"cells\": [\\n+  {\\n+   ...</td>\n",
       "      <td>add a notebook to the default cell_type</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       Hash  \\\n",
       "0  d2fdcba29db2a88056cfa87d9abfbdde840bd8c2   \n",
       "1  6a3dca888ba75e219185c54cd0f0ba72d1f90a26   \n",
       "2  90a6e578bc8d2147f5fcc22d6413686027eca2b5   \n",
       "3  eb36317f9ae6054a9bbf62ac7ceb8bae388ee811   \n",
       "4  eb36317f9ae6054a9bbf62ac7ceb8bae388ee811   \n",
       "\n",
       "                                             Message  \\\n",
       "0                                fix test name (#22)   \n",
       "1  Fix cohere integration (#33)\\n\\nCurrently the ...   \n",
       "2                                fix type hint (#34)   \n",
       "3  Harrison/fix imports (#72)\\n\\nfix imports and ...   \n",
       "4  Harrison/fix imports (#72)\\n\\nfix imports and ...   \n",
       "\n",
       "                          Hashes of parents Is a merge commit?  \\\n",
       "0  21b10ffb130aeac3131899e551939338b0dcebef                 No   \n",
       "1  c7f9c62532f8137db2c4ab80335ac1472e79d56a                 No   \n",
       "2  6a3dca888ba75e219185c54cd0f0ba72d1f90a26                 No   \n",
       "3  a5b61d59e193c4f9804c9dece7bd1a1c5c1103e0                 No   \n",
       "4  a5b61d59e193c4f9804c9dece7bd1a1c5c1103e0                 No   \n",
       "\n",
       "           Filename                               Source Code (before)  \\\n",
       "0    test_openai.py  \"\"\"Test OpenAI API wrapper.\"\"\"\\n\\nfrom langcha...   \n",
       "1         cohere.py  \"\"\"Wrapper around Cohere APIs.\"\"\"\\nimport os\\n...   \n",
       "2         cohere.py  \"\"\"Wrapper around Cohere APIs.\"\"\"\\nimport os\\n...   \n",
       "3  embeddings.ipynb  {\\n \"cells\": [\\n  {\\n   \"cell_type\": \"code\",\\n...   \n",
       "4        mrkl.ipynb  {\\n \"cells\": [\\n  {\\n   \"cell_type\": \"code\",\\n...   \n",
       "\n",
       "                               Source Code (current)  \\\n",
       "0  \"\"\"Test OpenAI API wrapper.\"\"\"\\n\\nfrom langcha...   \n",
       "1  \"\"\"Wrapper around Cohere APIs.\"\"\"\\nimport os\\n...   \n",
       "2  \"\"\"Wrapper around Cohere APIs.\"\"\"\\nimport os\\n...   \n",
       "3  {\\n \"cells\": [\\n  {\\n   \"cell_type\": \"code\",\\n...   \n",
       "4  {\\n \"cells\": [\\n  {\\n   \"cell_type\": \"markdown...   \n",
       "\n",
       "                                                Diff  \\\n",
       "0  @@ -3,8 +3,8 @@\\n from langchain.llms.openai i...   \n",
       "1  @@ -22,7 +22,7 @@ class Cohere(BaseModel, LLM)...   \n",
       "2  @@ -22,7 +22,7 @@ class Cohere(BaseModel, LLM)...   \n",
       "3  @@ -5,11 +5,26 @@\\n    \"execution_count\": 1,\\n...   \n",
       "4  @@ -1,5 +1,14 @@\\n {\\n  \"cells\": [\\n+  {\\n+   ...   \n",
       "\n",
       "                             LLM Inference  \n",
       "0                    add missing docstring  \n",
       "1    model attribute for gptd-instruct-tft  \n",
       "2   model attribute for model_name_to_json  \n",
       "3                     update error message  \n",
       "4  add a notebook to the default cell_type  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e7d7de7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "curr = df.iloc[:1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ba61a987",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Surrya Gokul\\AppData\\Local\\Temp\\ipykernel_12596\\944174093.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  curr[\"Diff\"] = curr[\"Diff\"].astype(str)\n",
      "C:\\Users\\Surrya Gokul\\AppData\\Local\\Temp\\ipykernel_12596\\944174093.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  curr[\"Message\"] = curr[\"Message\"].astype(str)\n",
      "C:\\Users\\Surrya Gokul\\AppData\\Local\\Temp\\ipykernel_12596\\944174093.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  curr[\"LLM Inference\"] = curr[\"LLM Inference\"].astype(str)\n"
     ]
    }
   ],
   "source": [
    "curr[\"Diff\"] = curr[\"Diff\"].astype(str)\n",
    "curr[\"Message\"] = curr[\"Message\"].astype(str)\n",
    "curr[\"LLM Inference\"] = curr[\"LLM Inference\"].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c503acd4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n: 1000\n",
      "dev hit: 0.0511482254697286\n",
      "llm hit: 0.15553235908141963\n",
      "rect hit: 0.1722338204592902\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "from collections import Counter\n",
    "from typing import Set, Tuple, List, Dict\n",
    "\n",
    "# Regex to find identifiers (like variable names)\n",
    "IDENT_RE = re.compile(r\"[A-Za-z_][A-Za-z0-9_]{2,60}\")\n",
    "\n",
    "def split_identifier_tokens(identifier: str) -> List[str]:\n",
    "    if not identifier:\n",
    "        return []\n",
    "    s = re.sub(r'[^0-9A-Za-z]+', '_', identifier.strip())  \n",
    "    parts = [p for p in s.split('_') if p]  \n",
    "    tokens = []\n",
    "    for p in parts:\n",
    "        # Try to split camelCase or numbers\n",
    "        camel_split = re.findall(r'[A-Z]?[a-z]+|[A-Z]+(?![a-z])|\\d+', p)\n",
    "        if camel_split:\n",
    "            tokens.extend([t.lower() for t in camel_split])\n",
    "        else:\n",
    "            tokens.append(p.lower())\n",
    "    return [t for t in tokens if len(t) > 1] \n",
    "\n",
    "def extract_identifiers(text: str) -> List[str]:\n",
    "    if not text:\n",
    "        return []\n",
    "    matches = IDENT_RE.findall(text)  \n",
    "    tokens = []\n",
    "    for m in matches:\n",
    "        tokens.extend(split_identifier_tokens(m))\n",
    "    return tokens\n",
    "\n",
    "def parse_diff_ids(diff_text: str) -> Tuple[Set[str], List[Tuple[str, int]]]:\n",
    "    if diff_text is None:\n",
    "        diff_text = \"\"\n",
    "    lines = diff_text.splitlines()\n",
    "    changed = [l[1:] for l in lines if l.startswith('+') or l.startswith('-')]  \n",
    "    header = [l for l in lines[:6] if l.startswith('+++') or l.startswith('---') or l.startswith('diff ')]  # First few lines\n",
    "    blob = \" \".join(changed + header) \n",
    "    tokens = extract_identifiers(blob) \n",
    "    counter = Counter(tokens)  \n",
    "    top = counter.most_common(10)  \n",
    "    return set(counter.keys()), top\n",
    "\n",
    "def jaccard_sets(a: Set[str], b: Set[str]) -> float:\n",
    "    if not a or not b:\n",
    "        return 0.0\n",
    "    inter = a & b  \n",
    "    uni = a | b  \n",
    "    return len(inter) / len(uni) if uni else 0.0  \n",
    "\n",
    "def build_template_from_ids(diff_text: str) -> str:\n",
    "    ids_set, top_list = parse_diff_ids(diff_text)\n",
    "    if not top_list: \n",
    "        return \"Fix bug\"\n",
    "    top_token = top_list[0][0]  \n",
    "    second = top_list[1][0] if len(top_list) > 1 and top_list[1][0] != top_token else None\n",
    "    if second:\n",
    "        return f\"Fix issue in {top_token} (related to {second})\"\n",
    "    return f\"Fix bug in {top_token}\"\n",
    "\n",
    "def rectify_by_identifiers(diff_text: str, dev_msg: str, llm_msg: str, replace_threshold: float = 0.25) -> Dict:\n",
    "    diff_ids_set, _ = parse_diff_ids(diff_text)\n",
    "    dev_ids = set(extract_identifiers(dev_msg))\n",
    "    llm_ids = set(extract_identifiers(llm_msg))\n",
    "    templ = build_template_from_ids(diff_text)\n",
    "    templ_ids = set(extract_identifiers(templ))\n",
    "\n",
    "    dev_score = jaccard_sets(diff_ids_set, dev_ids)\n",
    "    llm_score = jaccard_sets(diff_ids_set, llm_ids)\n",
    "    templ_score = jaccard_sets(diff_ids_set, templ_ids)\n",
    "\n",
    "    chosen = dev_msg\n",
    "    chosen_type = \"dev\"\n",
    "    if (templ_score > max(dev_score, llm_score)) and (templ_score >= replace_threshold):\n",
    "        chosen = templ\n",
    "        chosen_type = \"template\"\n",
    "\n",
    "    return {\n",
    "        'rect_msg': chosen,\n",
    "        'dev_score': dev_score,\n",
    "        'llm_score': llm_score,\n",
    "        'templ_score': templ_score,\n",
    "        'chosen_type': chosen_type,\n",
    "        'diff_ids': sorted(list(diff_ids_set))[:12],\n",
    "        'templ': templ\n",
    "    }\n",
    "\n",
    "def compute_hit_rates_identifier_only(df: pd.DataFrame,\n",
    "                                      hit_threshold: float = 0.2,\n",
    "                                      replace_threshold: float = 0.25,\n",
    "                                      drop_empty_diff: bool = True) -> Dict:\n",
    "    in_df = df.copy().reset_index(drop=True)\n",
    "    results = []\n",
    "    for idx, row in in_df.iterrows():\n",
    "        diff_text = str(row.get('Diff', '') or '')\n",
    "        dev_msg = str(row.get('Message', '') or '')\n",
    "        llm_msg = str(row.get('LLM Inference', '') or '')\n",
    "        res = rectify_by_identifiers(diff_text, dev_msg, llm_msg, replace_threshold=replace_threshold)\n",
    "        results.append(res)\n",
    "\n",
    "    res_df = pd.DataFrame(results)\n",
    "    out_df = pd.concat([in_df, res_df], axis=1)\n",
    "\n",
    "    rect_scores = []\n",
    "    for _, row in out_df.iterrows():\n",
    "        diff_ids_set, _ = parse_diff_ids(str(row.get('Diff', '') or ''))\n",
    "        rect_ids = set(extract_identifiers(str(row.get('rect_msg', '') or '')))\n",
    "        rect_scores.append(jaccard_sets(diff_ids_set, rect_ids))\n",
    "    out_df['rect_score'] = rect_scores\n",
    "\n",
    "    eval_mask = out_df['diff_ids'].apply(lambda x: bool(x))  \n",
    "    if drop_empty_diff:\n",
    "        evaluable_df = out_df[eval_mask].reset_index(drop=True)\n",
    "    else:\n",
    "        evaluable_df = out_df.copy()\n",
    "\n",
    "    n_total = len(out_df)\n",
    "    n_evaluable = len(evaluable_df)\n",
    "\n",
    "    dev_hits = (evaluable_df['dev_score'] >= hit_threshold).sum() if n_evaluable else 0\n",
    "    llm_hits = (evaluable_df['llm_score'] >= hit_threshold).sum() if n_evaluable else 0\n",
    "    rect_hits = (evaluable_df['rect_score'] >= hit_threshold).sum() if n_evaluable else 0\n",
    "\n",
    "    dev_rate = float(dev_hits) / n_evaluable if n_evaluable else 0.0\n",
    "    llm_rate = float(llm_hits) / n_evaluable if n_evaluable else 0.0\n",
    "    rect_rate = float(rect_hits) / n_evaluable if n_evaluable else 0.0\n",
    "\n",
    "    return {\n",
    "        'n_total': n_total,\n",
    "        'n_evaluable': n_evaluable,\n",
    "        'dev_hit_rate': dev_rate,\n",
    "        'llm_hit_rate': llm_rate,\n",
    "        'rect_hit_rate': rect_rate,\n",
    "        'df': out_df\n",
    "    }\n",
    "\n",
    "df = curr\n",
    "res = compute_hit_rates_identifier_only(df, hit_threshold=0.2, replace_threshold=0.25)\n",
    "print(\"n:\", res['n_total'])\n",
    "print(\"dev hit:\", res['dev_hit_rate'])\n",
    "print(\"llm hit:\", res['llm_hit_rate'])\n",
    "print(\"rect hit:\", res['rect_hit_rate'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "02066431",
   "metadata": {},
   "outputs": [],
   "source": [
    "res[\"df\"].columns = [['Hash', 'Message', 'Hashes of parents', 'Is a merge commit?',\n",
    "       'Filename', 'Source Code (before)', 'Source Code (current)', 'Diff',\n",
    "       'LLM Inference', 'Rectified Message']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "da45eaa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "res[\"df\"] = res[\"df\"][['Hash', 'Message', 'Hashes of parents', 'Is a merge commit?',\n",
    "       'Filename', 'Source Code (before)', 'Source Code (current)', 'Diff',\n",
    "       'LLM Inference', 'rect_msg']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "aff78bc8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>Hash</th>\n",
       "      <th>Message</th>\n",
       "      <th>Hashes of parents</th>\n",
       "      <th>Is a merge commit?</th>\n",
       "      <th>Filename</th>\n",
       "      <th>Source Code (before)</th>\n",
       "      <th>Source Code (current)</th>\n",
       "      <th>Diff</th>\n",
       "      <th>LLM Inference</th>\n",
       "      <th>Rectified Message</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>d2fdcba29db2a88056cfa87d9abfbdde840bd8c2</td>\n",
       "      <td>fix test name (#22)</td>\n",
       "      <td>21b10ffb130aeac3131899e551939338b0dcebef</td>\n",
       "      <td>No</td>\n",
       "      <td>test_openai.py</td>\n",
       "      <td>\"\"\"Test OpenAI API wrapper.\"\"\"\\n\\nfrom langcha...</td>\n",
       "      <td>\"\"\"Test OpenAI API wrapper.\"\"\"\\n\\nfrom langcha...</td>\n",
       "      <td>@@ -3,8 +3,8 @@\\n from langchain.llms.openai i...</td>\n",
       "      <td>add missing docstring</td>\n",
       "      <td>fix test name (#22)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6a3dca888ba75e219185c54cd0f0ba72d1f90a26</td>\n",
       "      <td>Fix cohere integration (#33)\\n\\nCurrently the ...</td>\n",
       "      <td>c7f9c62532f8137db2c4ab80335ac1472e79d56a</td>\n",
       "      <td>No</td>\n",
       "      <td>cohere.py</td>\n",
       "      <td>\"\"\"Wrapper around Cohere APIs.\"\"\"\\nimport os\\n...</td>\n",
       "      <td>\"\"\"Wrapper around Cohere APIs.\"\"\"\\nimport os\\n...</td>\n",
       "      <td>@@ -22,7 +22,7 @@ class Cohere(BaseModel, LLM)...</td>\n",
       "      <td>model attribute for gptd-instruct-tft</td>\n",
       "      <td>Fix cohere integration (#33)\\n\\nCurrently the ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>90a6e578bc8d2147f5fcc22d6413686027eca2b5</td>\n",
       "      <td>fix type hint (#34)</td>\n",
       "      <td>6a3dca888ba75e219185c54cd0f0ba72d1f90a26</td>\n",
       "      <td>No</td>\n",
       "      <td>cohere.py</td>\n",
       "      <td>\"\"\"Wrapper around Cohere APIs.\"\"\"\\nimport os\\n...</td>\n",
       "      <td>\"\"\"Wrapper around Cohere APIs.\"\"\"\\nimport os\\n...</td>\n",
       "      <td>@@ -22,7 +22,7 @@ class Cohere(BaseModel, LLM)...</td>\n",
       "      <td>model attribute for model_name_to_json</td>\n",
       "      <td>Fix issue in model (related to str)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>eb36317f9ae6054a9bbf62ac7ceb8bae388ee811</td>\n",
       "      <td>Harrison/fix imports (#72)\\n\\nfix imports and ...</td>\n",
       "      <td>a5b61d59e193c4f9804c9dece7bd1a1c5c1103e0</td>\n",
       "      <td>No</td>\n",
       "      <td>embeddings.ipynb</td>\n",
       "      <td>{\\n \"cells\": [\\n  {\\n   \"cell_type\": \"code\",\\n...</td>\n",
       "      <td>{\\n \"cells\": [\\n  {\\n   \"cell_type\": \"code\",\\n...</td>\n",
       "      <td>@@ -5,11 +5,26 @@\\n    \"execution_count\": 1,\\n...</td>\n",
       "      <td>update error message</td>\n",
       "      <td>Harrison/fix imports (#72)\\n\\nfix imports and ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>eb36317f9ae6054a9bbf62ac7ceb8bae388ee811</td>\n",
       "      <td>Harrison/fix imports (#72)\\n\\nfix imports and ...</td>\n",
       "      <td>a5b61d59e193c4f9804c9dece7bd1a1c5c1103e0</td>\n",
       "      <td>No</td>\n",
       "      <td>mrkl.ipynb</td>\n",
       "      <td>{\\n \"cells\": [\\n  {\\n   \"cell_type\": \"code\",\\n...</td>\n",
       "      <td>{\\n \"cells\": [\\n  {\\n   \"cell_type\": \"markdown...</td>\n",
       "      <td>@@ -1,5 +1,14 @@\\n {\\n  \"cells\": [\\n+  {\\n+   ...</td>\n",
       "      <td>add a notebook to the default cell_type</td>\n",
       "      <td>Harrison/fix imports (#72)\\n\\nfix imports and ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>08876ad0660222fcc481175639c59ce9f2b110bb</td>\n",
       "      <td>Fix SelfQueryRetriever, passing new query to v...</td>\n",
       "      <td>8fd4d5d11752ad268f8af90f39e73742d89197fc</td>\n",
       "      <td>No</td>\n",
       "      <td>base.py</td>\n",
       "      <td>\"\"\"Retriever that generates and executes struc...</td>\n",
       "      <td>\"\"\"Retriever that generates and executes struc...</td>\n",
       "      <td>@@ -81,7 +81,7 @@ class SelfQueryRetriever(Bas...</td>\n",
       "      <td>fix bug in vectorstore search</td>\n",
       "      <td>Fix SelfQueryRetriever, passing new query to v...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>11341fcecbb92ccdb8ee2edf72c83342ed59f6fd</td>\n",
       "      <td>Fixed query checker for SQLDatabaseChain (#478...</td>\n",
       "      <td>08876ad0660222fcc481175639c59ce9f2b110bb</td>\n",
       "      <td>No</td>\n",
       "      <td>base.py</td>\n",
       "      <td>\"\"\"Chain for interacting with SQL Database.\"\"\"...</td>\n",
       "      <td>\"\"\"Chain for interacting with SQL Database.\"\"\"...</td>\n",
       "      <td>@@ -130,7 +130,7 @@ class SQLDatabaseChain(Cha...</td>\n",
       "      <td>fix llm prompt</td>\n",
       "      <td>Fixed query checker for SQLDatabaseChain (#478...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>e28f4a5f391bc8c90079c26d3ba92256e1d589a9</td>\n",
       "      <td>changed cohere.py to update the default model ...</td>\n",
       "      <td>75fe9d3555d118e21650445ef1a390e8726ced00</td>\n",
       "      <td>No</td>\n",
       "      <td>cohere.py</td>\n",
       "      <td>\"\"\"Wrapper around Cohere embedding models.\"\"\"\\...</td>\n",
       "      <td>\"\"\"Wrapper around Cohere embedding models.\"\"\"\\...</td>\n",
       "      <td>@@ -18,11 +18,13 @@ class CohereEmbeddings(Bas...</td>\n",
       "      <td>fix typo in example</td>\n",
       "      <td>changed cohere.py to update the default model ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>432421ffa50c44e660b902adb48db40add9621d5</td>\n",
       "      <td>[Fix][GenerativeAgent] Get the memory importan...</td>\n",
       "      <td>be405ac1398abd9335b93bf7567e02f0381d5811</td>\n",
       "      <td>No</td>\n",
       "      <td>memory.py</td>\n",
       "      <td>import logging\\nimport re\\nfrom datetime impor...</td>\n",
       "      <td>import logging\\nimport re\\nfrom datetime impor...</td>\n",
       "      <td>@@ -123,7 +123,7 @@ class GenerativeAgentMemor...</td>\n",
       "      <td>fix importance</td>\n",
       "      <td>[Fix][GenerativeAgent] Get the memory importan...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>6fbd5e837f3b987295e6f68c8d54d64437bc33d0</td>\n",
       "      <td>Update planner_prompt.py, change usery to user...</td>\n",
       "      <td>432421ffa50c44e660b902adb48db40add9621d5</td>\n",
       "      <td>No</td>\n",
       "      <td>planner_prompt.py</td>\n",
       "      <td># flake8: noqa\\n\\nfrom langchain.prompts.promp...</td>\n",
       "      <td># flake8: noqa\\n\\nfrom langchain.prompts.promp...</td>\n",
       "      <td>@@ -29,7 +29,7 @@ DELETE /users/{{id}}/cart to...</td>\n",
       "      <td>add missing word</td>\n",
       "      <td>Update planner_prompt.py, change usery to user...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         Hash  \\\n",
       "0    d2fdcba29db2a88056cfa87d9abfbdde840bd8c2   \n",
       "1    6a3dca888ba75e219185c54cd0f0ba72d1f90a26   \n",
       "2    90a6e578bc8d2147f5fcc22d6413686027eca2b5   \n",
       "3    eb36317f9ae6054a9bbf62ac7ceb8bae388ee811   \n",
       "4    eb36317f9ae6054a9bbf62ac7ceb8bae388ee811   \n",
       "..                                        ...   \n",
       "995  08876ad0660222fcc481175639c59ce9f2b110bb   \n",
       "996  11341fcecbb92ccdb8ee2edf72c83342ed59f6fd   \n",
       "997  e28f4a5f391bc8c90079c26d3ba92256e1d589a9   \n",
       "998  432421ffa50c44e660b902adb48db40add9621d5   \n",
       "999  6fbd5e837f3b987295e6f68c8d54d64437bc33d0   \n",
       "\n",
       "                                               Message  \\\n",
       "0                                  fix test name (#22)   \n",
       "1    Fix cohere integration (#33)\\n\\nCurrently the ...   \n",
       "2                                  fix type hint (#34)   \n",
       "3    Harrison/fix imports (#72)\\n\\nfix imports and ...   \n",
       "4    Harrison/fix imports (#72)\\n\\nfix imports and ...   \n",
       "..                                                 ...   \n",
       "995  Fix SelfQueryRetriever, passing new query to v...   \n",
       "996  Fixed query checker for SQLDatabaseChain (#478...   \n",
       "997  changed cohere.py to update the default model ...   \n",
       "998  [Fix][GenerativeAgent] Get the memory importan...   \n",
       "999  Update planner_prompt.py, change usery to user...   \n",
       "\n",
       "                            Hashes of parents Is a merge commit?  \\\n",
       "0    21b10ffb130aeac3131899e551939338b0dcebef                 No   \n",
       "1    c7f9c62532f8137db2c4ab80335ac1472e79d56a                 No   \n",
       "2    6a3dca888ba75e219185c54cd0f0ba72d1f90a26                 No   \n",
       "3    a5b61d59e193c4f9804c9dece7bd1a1c5c1103e0                 No   \n",
       "4    a5b61d59e193c4f9804c9dece7bd1a1c5c1103e0                 No   \n",
       "..                                        ...                ...   \n",
       "995  8fd4d5d11752ad268f8af90f39e73742d89197fc                 No   \n",
       "996  08876ad0660222fcc481175639c59ce9f2b110bb                 No   \n",
       "997  75fe9d3555d118e21650445ef1a390e8726ced00                 No   \n",
       "998  be405ac1398abd9335b93bf7567e02f0381d5811                 No   \n",
       "999  432421ffa50c44e660b902adb48db40add9621d5                 No   \n",
       "\n",
       "              Filename                               Source Code (before)  \\\n",
       "0       test_openai.py  \"\"\"Test OpenAI API wrapper.\"\"\"\\n\\nfrom langcha...   \n",
       "1            cohere.py  \"\"\"Wrapper around Cohere APIs.\"\"\"\\nimport os\\n...   \n",
       "2            cohere.py  \"\"\"Wrapper around Cohere APIs.\"\"\"\\nimport os\\n...   \n",
       "3     embeddings.ipynb  {\\n \"cells\": [\\n  {\\n   \"cell_type\": \"code\",\\n...   \n",
       "4           mrkl.ipynb  {\\n \"cells\": [\\n  {\\n   \"cell_type\": \"code\",\\n...   \n",
       "..                 ...                                                ...   \n",
       "995            base.py  \"\"\"Retriever that generates and executes struc...   \n",
       "996            base.py  \"\"\"Chain for interacting with SQL Database.\"\"\"...   \n",
       "997          cohere.py  \"\"\"Wrapper around Cohere embedding models.\"\"\"\\...   \n",
       "998          memory.py  import logging\\nimport re\\nfrom datetime impor...   \n",
       "999  planner_prompt.py  # flake8: noqa\\n\\nfrom langchain.prompts.promp...   \n",
       "\n",
       "                                 Source Code (current)  \\\n",
       "0    \"\"\"Test OpenAI API wrapper.\"\"\"\\n\\nfrom langcha...   \n",
       "1    \"\"\"Wrapper around Cohere APIs.\"\"\"\\nimport os\\n...   \n",
       "2    \"\"\"Wrapper around Cohere APIs.\"\"\"\\nimport os\\n...   \n",
       "3    {\\n \"cells\": [\\n  {\\n   \"cell_type\": \"code\",\\n...   \n",
       "4    {\\n \"cells\": [\\n  {\\n   \"cell_type\": \"markdown...   \n",
       "..                                                 ...   \n",
       "995  \"\"\"Retriever that generates and executes struc...   \n",
       "996  \"\"\"Chain for interacting with SQL Database.\"\"\"...   \n",
       "997  \"\"\"Wrapper around Cohere embedding models.\"\"\"\\...   \n",
       "998  import logging\\nimport re\\nfrom datetime impor...   \n",
       "999  # flake8: noqa\\n\\nfrom langchain.prompts.promp...   \n",
       "\n",
       "                                                  Diff  \\\n",
       "0    @@ -3,8 +3,8 @@\\n from langchain.llms.openai i...   \n",
       "1    @@ -22,7 +22,7 @@ class Cohere(BaseModel, LLM)...   \n",
       "2    @@ -22,7 +22,7 @@ class Cohere(BaseModel, LLM)...   \n",
       "3    @@ -5,11 +5,26 @@\\n    \"execution_count\": 1,\\n...   \n",
       "4    @@ -1,5 +1,14 @@\\n {\\n  \"cells\": [\\n+  {\\n+   ...   \n",
       "..                                                 ...   \n",
       "995  @@ -81,7 +81,7 @@ class SelfQueryRetriever(Bas...   \n",
       "996  @@ -130,7 +130,7 @@ class SQLDatabaseChain(Cha...   \n",
       "997  @@ -18,11 +18,13 @@ class CohereEmbeddings(Bas...   \n",
       "998  @@ -123,7 +123,7 @@ class GenerativeAgentMemor...   \n",
       "999  @@ -29,7 +29,7 @@ DELETE /users/{{id}}/cart to...   \n",
       "\n",
       "                               LLM Inference  \\\n",
       "0                      add missing docstring   \n",
       "1      model attribute for gptd-instruct-tft   \n",
       "2     model attribute for model_name_to_json   \n",
       "3                       update error message   \n",
       "4    add a notebook to the default cell_type   \n",
       "..                                       ...   \n",
       "995            fix bug in vectorstore search   \n",
       "996                           fix llm prompt   \n",
       "997                      fix typo in example   \n",
       "998                           fix importance   \n",
       "999                         add missing word   \n",
       "\n",
       "                                     Rectified Message  \n",
       "0                                  fix test name (#22)  \n",
       "1    Fix cohere integration (#33)\\n\\nCurrently the ...  \n",
       "2                  Fix issue in model (related to str)  \n",
       "3    Harrison/fix imports (#72)\\n\\nfix imports and ...  \n",
       "4    Harrison/fix imports (#72)\\n\\nfix imports and ...  \n",
       "..                                                 ...  \n",
       "995  Fix SelfQueryRetriever, passing new query to v...  \n",
       "996  Fixed query checker for SQLDatabaseChain (#478...  \n",
       "997  changed cohere.py to update the default model ...  \n",
       "998  [Fix][GenerativeAgent] Get the memory importan...  \n",
       "999  Update planner_prompt.py, change usery to user...  \n",
       "\n",
       "[1000 rows x 10 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res[\"df\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ef4ae3d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "res[\"df\"].to_csv(\"Lab2final.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa2fb28c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved assets to report_assets\n",
      "McNemar: {'b': 142, 'c': 126, 'chi2': 0.8395522388059702, 'p': 0.35952486213934653}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Surrya Gokul\\AppData\\Local\\Temp\\ipykernel_43700\\4008949819.py:87: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  ex_table[['Message', 'LLM Inference', 'rect_msg']] = ex_table[['Message', 'LLM Inference', 'rect_msg']].applymap(\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats\n",
    "\n",
    "OUT_DIR = \"report_assets\"\n",
    "os.makedirs(OUT_DIR, exist_ok=True)\n",
    "\n",
    "def save_summary_table(res, out_path=os.path.join(OUT_DIR, \"summary_table.tex\")):\n",
    "    n_total = res.get('n_total', len(res['df']))\n",
    "    n_eval = res.get('n_evaluable', len(res['df']))\n",
    "    dev = res['dev_hit_rate']\n",
    "    llm = res['llm_hit_rate']\n",
    "    rect = res['rect_hit_rate']\n",
    "    replacement_count = (res['df']['chosen_type'] == 'template').sum()\n",
    "    replacement_rate = replacement_count / n_eval if n_eval else 0.0\n",
    "\n",
    "    summary = pd.DataFrame([{\n",
    "        \"n_total\": n_total,\n",
    "        \"n_evaluable\": n_eval,\n",
    "        \"dev_hit\": dev,\n",
    "        \"llm_hit\": llm,\n",
    "        \"rect_hit\": rect,\n",
    "        \"replacement_count\": replacement_count,\n",
    "        \"replacement_rate\": replacement_rate\n",
    "    }])\n",
    "    latex = summary.to_latex(index=False, float_format=\"%.3f\", caption=\"Summary hit rates and replacements\", label=\"tab:summary\", column_format='lrrrrrr', longtable=False, header=True)\n",
    "    with open(out_path, \"w\") as f:\n",
    "        f.write(latex)\n",
    "    return summary\n",
    "\n",
    "def plot_hit_rates_bar(res, out_png=os.path.join(OUT_DIR, \"hit_rates_bar.png\")):\n",
    "    vals = [res['dev_hit_rate'], res['llm_hit_rate'], res['rect_hit_rate']]\n",
    "    labels = ['Developer', 'LLM', 'Rectifier']\n",
    "    fig, ax = plt.subplots(figsize=(6, 4))\n",
    "    bars = ax.bar(labels, vals, edgecolor='k')\n",
    "    ax.set_ylim(0, max(0.6, max(vals) * 1.15))\n",
    "    ax.set_ylabel(\"Hit rate\")\n",
    "    ax.set_title(\"Hit rates (per-file, evaluable samples)\")\n",
    "    for bar, val in zip(bars, vals):\n",
    "        ax.text(bar.get_x() + bar.get_width() / 2, val + 0.01, f\"{val:.3f}\", ha='center')\n",
    "    plt.tight_layout()\n",
    "    fig.savefig(out_png, dpi=200)\n",
    "    plt.close(fig)\n",
    "\n",
    "def plot_rect_score_hist(df, out_png=os.path.join(OUT_DIR, \"rect_score_hist.png\")):\n",
    "    vals = df['rect_score'].dropna()\n",
    "    fig, ax = plt.subplots(figsize=(6, 4))\n",
    "    ax.hist(vals, bins=20, edgecolor='k')\n",
    "    ax.set_title(\"Distribution of rectifier Jaccard scores\")\n",
    "    ax.set_xlabel(\"rect_score\")\n",
    "    ax.set_ylabel(\"count\")\n",
    "    plt.tight_layout()\n",
    "    fig.savefig(out_png, dpi=200)\n",
    "    plt.close(fig)\n",
    "\n",
    "def plot_replacement_breakdown(df, out_png=os.path.join(OUT_DIR, \"replacement_breakdown_bar.png\")):\n",
    "    counts = df['chosen_type'].value_counts()\n",
    "    fig, ax = plt.subplots(figsize=(6, 4))\n",
    "    counts.plot(kind='bar', ax=ax)\n",
    "    ax.set_title(\"Rectifier chosen type distribution\")\n",
    "    ax.set_ylabel(\"count\")\n",
    "    for i, v in enumerate(counts.values):\n",
    "        ax.text(i, v + max(counts.values) * 0.01, str(v), ha='center')\n",
    "    plt.tight_layout()\n",
    "    fig.savefig(out_png, dpi=200)\n",
    "    plt.close(fig)\n",
    "\n",
    "def save_examples_table(df, out_tex=os.path.join(OUT_DIR, \"top_examples.tex\"), n=10):\n",
    "    replaced = df[df['chosen_type'] == 'template']\n",
    "    top = replaced.sort_values('rect_score', ascending=False).head(n // 2)\n",
    "    bot = replaced.sort_values('rect_score', ascending=True).head(n // 2)\n",
    "    ex = pd.concat([top, bot])\n",
    "    ex_table = ex[['Diff', 'Message', 'LLM Inference', 'rect_msg', 'dev_score', 'llm_score', 'templ_score', 'rect_score', 'chosen_type']].copy()\n",
    "    ex_table['Diff'] = ex_table['Diff'].str.replace(r'\\s+', ' ', regex=True).str.slice(0, 120)\n",
    "    ex_table[['Message', 'LLM Inference', 'rect_msg']] = ex_table[['Message', 'LLM Inference', 'rect_msg']].applymap(\n",
    "        lambda s: (s[:80] + '...') if isinstance(s, str) and len(s) > 80 else s)\n",
    "    latex = ex_table.to_latex(index=False, escape=True, column_format='p{3cm}p{2.2cm}p{2.2cm}p{2.2cm}rrrrc', caption=\"Representative rectifier examples\", label=\"tab:examples\")\n",
    "    with open(out_tex, \"w\") as f:\n",
    "        f.write(latex)\n",
    "    return ex_table\n",
    "\n",
    "def sensitivity_curve(df, thresholds=np.linspace(0.05, 0.6, 12), hit_thr=0.2, out_png=os.path.join(OUT_DIR, \"sensitivity_curve.png\")):\n",
    "    rect_rates = []\n",
    "    n_eval = (df['diff_ids'].apply(bool)).sum()\n",
    "    for t in thresholds:\n",
    "        templ_better = (df['templ_score'] > df['dev_score']) & (df['templ_score'] > df['llm_score']) & (df['templ_score'] >= t)\n",
    "        rect_score = np.where(templ_better, df['templ_score'], df['dev_score'])\n",
    "        mask = df['diff_ids'].apply(bool)\n",
    "        rect_hit = ((rect_score >= hit_thr) & mask).sum()\n",
    "        rect_rates.append(rect_hit / mask.sum() if mask.sum() else 0.0)\n",
    "    fig, ax = plt.subplots(figsize=(6, 4))\n",
    "    ax.plot(thresholds, rect_rates, marker='o')\n",
    "    ax.set_xlabel(\"replace_threshold (templ_score)\")\n",
    "    ax.set_ylabel(\"Rectifier hit rate\")\n",
    "    ax.set_title(\"Sensitivity of rectifier to replace_threshold\")\n",
    "    plt.grid(True)\n",
    "    plt.tight_layout()\n",
    "    fig.savefig(out_png, dpi=200)\n",
    "    plt.close(fig)\n",
    "    return thresholds, rect_rates\n",
    "\n",
    "summary = save_summary_table(res)\n",
    "plot_hit_rates_bar(res)\n",
    "plot_rect_score_hist(res['df'])\n",
    "plot_replacement_breakdown(res['df'])\n",
    "examples = save_examples_table(res['df'], n=10)\n",
    "s_thresh, s_rates = sensitivity_curve(res['df'])\n",
    "\n",
    "pd.DataFrame({\"threshold\": s_thresh, \"rect_rate\": s_rates}).to_csv(os.path.join(OUT_DIR, \"sensitivity.csv\"), index=False)\n",
    "\n",
    "print(\"Saved assets to\", OUT_DIR)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "genai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
